{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71f3d6e1-5237-40c2-9de0-2b0e43254861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers as hug\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=config)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e2faa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cab63c-9a47-43fe-b96c-494248dd3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_context('notebook', rc={'figure.figsize': (10, 6)}, font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6aa79f-70d9-4a7e-8670-e33774b5abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_input_data(filepath='./data/tweets.csv',encoding='cp1252'): #Change encoding if not on windows\n",
    "    tweets = pd.read_csv(filepath,encoding=encoding,header=None)\n",
    "    tweets.columns = ['target','id','date','flag','username','text'] #Change column names to things that make sense\n",
    "    tweets = tweets.drop(columns=['id','date','flag','username']) #Remove unneeded columns from memory\n",
    "\n",
    "    tweets = tweets.replace({'target':{0:0,4:1}}) #Dataset has only 0=negative sent, 4=positive sent, remappping to 0,1 respectivly\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ad574-d32b-4a85-9b88-4306fe5ece12",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pre_process_input_data(filepath= \"../data/tweets.csv\") #Change this to the filepath of the tweets file\n",
    "\n",
    "input_data['target'].hist()\n",
    "# input_data.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e3b889-5951-4bd3-b1c9-ffec40bafa3c",
   "metadata": {},
   "source": [
    "## HuggingFace Transformer\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "TOKENIZER = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "MODEL = TFBertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d05cfc-f6b3-4d5c-a668-1148de1b9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 30000\n",
    "subset = input_data.iloc[:num_samples]\n",
    "subset = pd.concat([subset,input_data.iloc[-1 * num_samples:]])\n",
    "\n",
    "# subset = input_data\n",
    "\n",
    "subset['target'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25631c2e-4d08-4e6e-9e1d-8085ed204317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# tens,attention = convert_to_encoded(\"Hello World I am\")\n",
    "def convert_df_to_encoded(df,text_col='text',model=MODEL,tokenizer=TOKENIZER,batch_size=500):\n",
    "\n",
    "    batches = [(i,min(i+batch_size,len(df))) for i in range(0,len(df),batch_size)] #Split into smaller chunks\n",
    "    _df = pd.DataFrame()\n",
    "    max_twt_len = np.max([len(v) for v in df[text_col]])\n",
    "    print(max_twt_len)\n",
    "    for lower,upper in tqdm(batches):\n",
    "        chunk = df.iloc[lower:upper]\n",
    "        features = tokenizer(chunk[text_col].values.tolist(),padding='max_length', truncation=True, return_tensors='tf',max_length=max_twt_len)\n",
    "        features = model(**features).last_hidden_state[:,0,:]\n",
    "        chunk['features'] = features.numpy().tolist()\n",
    "        _df = pd.concat([_df,chunk])\n",
    "    return _df\n",
    "#TODO: PCA compression on vectors down to 250 space for memory reasons\n",
    "\n",
    "\n",
    "# input_data.sort_values(by='target')\n",
    "\n",
    "tmp = convert_df_to_encoded(subset)\n",
    "# tmp = input_data['text'].apply(convert_to_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa3b34-5e58-450b-8006-96cee08d84b5",
   "metadata": {},
   "source": [
    "#### PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0b442-e0ca-4d4b-b112-776d2f00c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([x for x in tmp['features']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b03b1b-61c0-4be0-928e-b4b75694af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1e3de-279d-401f-af1d-31ca39118e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "vectors = x\n",
    "targets = tmp['target']\n",
    "labels = tmp['text']\n",
    "\n",
    "train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \\\n",
    "    train_test_split(vectors, targets, labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc4340-b060-43ce-839a-a52f8034ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, val_vectors, train_targets, val_targets, train_labels,val_labels = \\\n",
    "    train_test_split(train_vectors,train_targets,train_labels,test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb364d-1106-4b86-8337-16ab2db1b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=300)\n",
    "train_vectors = pca.fit_transform(train_vectors)\n",
    "val_vectors = pca.transform(val_vectors)\n",
    "test_vectors = pca.transform(test_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbcde52-b9df-434a-b505-6470f0203131",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Train Vector Shape: {train_vectors.shape}\n",
    "Validation Vector Shape: {val_vectors.shape}\n",
    "Test Vector Shape: {test_vectors.shape}\n",
    "\"\"\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be15ef-5d6c-4d8d-90e8-29b329142e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SGDClassifier(loss='log_loss', random_state=0, max_iter=500)\n",
    "classifier.fit(train_vectors, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896bda18-a959-4841-81d1-a907eae2a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(classifier.predict(test_vectors), test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b4c2e8a-0d26-4cc3-91d6-f5519b1d2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Input, Dropout, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aedc4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa8b0c-9bf3-45bf-9ce5-2c5108f22ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNetwork():\n",
    "    model = Sequential()\n",
    "    #embedding layer \n",
    "    model.add(tf.keras.Input(shape=(300,)))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=1e-3,\n",
    "    )\n",
    "    callbacks = []\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=0.001)) #Early stop\n",
    "    return model, callbacks\n",
    "mdl,callbacks = generateNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80539162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_seq_noGlove():\n",
    "        EMBED_SIZE = 100  # same size as loaded from GLOVE\n",
    "        sequence_input = Input(shape=(300,), dtype='int32')\n",
    "        x = Conv1D(128, 5, activation='relu', kernel_initializer='he_uniform')(sequence_input)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv1D(128, 5, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "        preds = Dense(3, activation='softmax', kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "        model = Model(sequence_input, preds)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', \n",
    "                optimizer='rmsprop',\n",
    "                metrics=['acc'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02714d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8401e1a-2d93-492f-a7e7-63efd2e77349",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045b982-a26a-476f-ada7-bc92b3320e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91335fe-fcdd-49d5-9caf-77e4cf383b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.fit(train_vectors,train_targets,epochs=200,validation_data=(val_vectors,val_targets),callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8b479-0d8e-436e-a571-923ce9f0b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(mdl.predict(test_vectors),test_targets)\n",
    "mdl.evaluate(test_vectors,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a59e811-21b7-4613-97df-a498c0e01b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059699f4-038a-4d44-a7a5-4df412554825",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mdl.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = pd.DataFrame({'predict':res.flatten(),'target':test_targets,'sentence':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 400)\n",
    "viewer['diff'] = abs(viewer['predict'] - viewer['target'])\n",
    "viewer.sort_values(by='diff').tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa28d161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6236476a-41e8-4a9d-8359-4ed6da5ec13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6415b860-4c7f-44fa-9961-f47f931a9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.iloc[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955cc8d-d002-46ef-aba7-9d8b288d0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.iloc[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7796fa-0046-4a9a-a16b-8f46f9c5f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stolen From Josh SYlvester\n",
    "# def make_neural_net_no_sentiment():\n",
    "#     # Create the model\n",
    "#     model = keras.Sequential([\n",
    "#         layers.Dense(units=128, activation='relu'),\n",
    "#         layers.Dense(units=64, activation='relu'),\n",
    "#         layers.Dense(units=1, activation='sigmoid')\n",
    "#     ])\n",
    "\n",
    "#     reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                                 patience=4, min_lr=0.000001, verbose=1)\n",
    "#     early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=0.001)\n",
    "\n",
    "#     callbacks = [early_stop, reduce_lr]\n",
    "#     optimizer = tf.keras.optimizers.Adam(\n",
    "#         learning_rate=1e-3,\n",
    "#     )\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer=optimizer,\n",
    "#                 loss='binary_crossentropy',\n",
    "#                 metrics=['accuracy'])\n",
    "\n",
    "#     return model, callbacks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
